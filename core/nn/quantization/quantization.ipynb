{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:36.925214Z",
     "start_time": "2025-12-16T18:30:35.478117Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = \"mps\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparation",
   "id": "60e6942db00ea57c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### mnist datasets & loader",
   "id": "da439f5711f09e44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:36.962109Z",
     "start_time": "2025-12-16T18:30:36.929554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# train\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "# test\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)"
   ],
   "id": "9b763d5c16f97c93",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### model",
   "id": "8dd093aa98be62f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:37.106849Z",
     "start_time": "2025-12-16T18:30:37.104135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Classification(nn.Module):\n",
    "    def __init__(self, hidden_size_1=128, hidden_size_2=128):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ],
   "id": "3fd5feddb5bb3d3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### train script",
   "id": "9177aec7bcfc82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:37.132679Z",
     "start_time": "2025-12-16T18:30:37.129197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
    "    cross_el = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(x.view(-1, 28*28))\n",
    "            loss = cross_el(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
    "                return\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove('temp_delme.p')"
   ],
   "id": "bba63d2e43b9e5b1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### test script",
   "id": "f0e0cd92e54ee840"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:37.153791Z",
     "start_time": "2025-12-16T18:30:37.150853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(model: nn.Module, total_iterations: int = None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing'):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x.view(-1, 784))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct +=1\n",
    "                total +=1\n",
    "            iterations += 1\n",
    "            if total_iterations is not None and iterations >= total_iterations:\n",
    "                break\n",
    "    print(f'Accuracy: {round(correct/total, 3)}')"
   ],
   "id": "7487a9cf4e4c5242",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train/Load Model",
   "id": "afaa526368eb2cd6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:37.201480Z",
     "start_time": "2025-12-16T18:30:37.175478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_FILENAME = 'simplenet_ptq.pt'\n",
    "\n",
    "net = Classification().to(device)\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print('Loaded model from disk')\n",
    "else:\n",
    "    train(train_loader, net, epochs=1)\n",
    "    torch.save(net.state_dict(), MODEL_FILENAME)"
   ],
   "id": "2fdbf5f5c5d8d240",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:42.849398Z",
     "start_time": "2025-12-16T18:30:37.211755Z"
    }
   },
   "cell_type": "code",
   "source": "test(net)",
   "id": "a637fd68f6cc1b4c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:05<00:00, 178.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# (PTQ) Post Training Quantisation",
   "id": "f252414d83327df2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:47.422331Z",
     "start_time": "2025-12-16T18:30:47.413926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchao.quantization import Int8DynamicActivationInt8WeightConfig\n",
    "from torchao.quantization import quantize_\n",
    "from copy import deepcopy\n",
    "\n",
    "q_net = deepcopy(net)\n",
    "quantize_(q_net, Int8DynamicActivationInt8WeightConfig())"
   ],
   "id": "28ebbd47f7a28067",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Inspect Models\n",
    "\n",
    "activation=\\<function _int8_symm_per_token_reduced_range_quant\\>:\n",
    "- INT8\n",
    "- symmetric (symm)\n",
    "- per-token (dynamic, runtime)\n",
    "- reduced range (e.g. [-127, 127])\n",
    "\n",
    "You do not see:\n",
    "- activation_scale\n",
    "- activation_zero_point\n",
    "- calibration observers\n",
    "Because they are computed on-the-fly.\n"
   ],
   "id": "7fd2f23d4492d2ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<img src=\"attachments/quant_3.png\" width=\"400\">",
   "id": "ac9210239d549a0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### model architecture",
   "id": "7769beb4597962b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:50.332791Z",
     "start_time": "2025-12-16T18:30:50.330515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(net)\n",
    "print(q_net)"
   ],
   "id": "de62a780aea3e0c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification(\n",
      "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (linear3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "Classification(\n",
      "  (linear1): Linear(in_features=784, out_features=128, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x167401f30>, weight=AffineQuantizedTensor(shape=torch.Size([128, 784]), block_size=(1, 784), device=mps:0, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
      "  (linear2): Linear(in_features=128, out_features=128, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x167401f30>, weight=AffineQuantizedTensor(shape=torch.Size([128, 128]), block_size=(1, 128), device=mps:0, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
      "  (linear3): Linear(in_features=128, out_features=10, weight=LinearActivationQuantizedTensor(activation=<function _int8_symm_per_token_reduced_range_quant at 0x167401f30>, weight=AffineQuantizedTensor(shape=torch.Size([10, 128]), block_size=(1, 128), device=mps:0, _layout=PlainLayout(), tensor_impl_dtype=torch.int8, quant_min=None, quant_max=None)))\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### original weight & bias",
   "id": "aff956d6516126ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:52.187457Z",
     "start_time": "2025-12-16T18:30:52.005323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(net.linear1.weight)\n",
    "print(net.linear1.bias)"
   ],
   "id": "2832339da8474ca7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0389,  0.0412,  0.0032,  ..., -0.0026,  0.0209,  0.0251],\n",
      "        [-0.0285, -0.0451,  0.0090,  ..., -0.0203, -0.0098,  0.0018],\n",
      "        [ 0.0225,  0.0249,  0.0278,  ...,  0.0106,  0.0044,  0.0291],\n",
      "        ...,\n",
      "        [-0.0007,  0.0222,  0.0490,  ...,  0.0158, -0.0129,  0.0316],\n",
      "        [ 0.0130,  0.0458,  0.0080,  ...,  0.0117,  0.0280,  0.0555],\n",
      "        [-0.0136,  0.0313,  0.0211,  ...,  0.0062,  0.0145,  0.0012]],\n",
      "       device='mps:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0125,  0.0362,  0.0010, -0.0220, -0.0636, -0.0202,  0.0311, -0.0310,\n",
      "        -0.0279, -0.0124,  0.0104,  0.0056,  0.0190, -0.0433, -0.0403, -0.0144,\n",
      "        -0.0422, -0.0489,  0.0070,  0.0476,  0.0027, -0.0185,  0.0521, -0.0434,\n",
      "        -0.0529, -0.0260, -0.0357, -0.0259, -0.0414, -0.0560,  0.0050, -0.0021,\n",
      "        -0.0013, -0.0516, -0.0169,  0.0261, -0.0083,  0.0039,  0.0015, -0.0128,\n",
      "         0.0150,  0.0152, -0.0263,  0.0036, -0.0391,  0.0013,  0.0054, -0.0354,\n",
      "        -0.0197, -0.0365,  0.0183, -0.0095, -0.0515,  0.0193, -0.0401, -0.0258,\n",
      "        -0.0026,  0.0073, -0.0221, -0.0204,  0.0244, -0.0195, -0.0295, -0.0185,\n",
      "        -0.0328, -0.0011, -0.0449, -0.0156,  0.0027,  0.0055, -0.0020,  0.0170,\n",
      "         0.0305, -0.0180, -0.0360, -0.0163, -0.0066, -0.0115, -0.0273,  0.0113,\n",
      "        -0.0047, -0.0318, -0.0680, -0.0423,  0.0062,  0.0374, -0.0256, -0.0036,\n",
      "        -0.0615, -0.0452,  0.0212, -0.0198, -0.0213,  0.0257, -0.0031, -0.0675,\n",
      "         0.0320,  0.0167, -0.0200, -0.0426, -0.0401, -0.0167,  0.0092, -0.0597,\n",
      "        -0.0090, -0.0219,  0.0069, -0.0165,  0.0375,  0.0109,  0.0306, -0.0130,\n",
      "        -0.0311,  0.0086,  0.0185,  0.0162, -0.0192, -0.0236, -0.0297, -0.0042,\n",
      "        -0.0669, -0.0272,  0.0122, -0.0574, -0.0008, -0.0544, -0.0315, -0.0061],\n",
      "       device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### quantized weight",
   "id": "c9562417ec2508ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:53.591417Z",
     "start_time": "2025-12-16T18:30:53.447601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(q_net.linear1.weight)\n",
    "print(q_net.linear1.bias)\n",
    "# bias is not quantized since it is usually int32 precision to match gpu accumulator\n",
    "# see last part in https://youtu.be/0VdNflU08yA?si=zTiAwwZ3W1YT-ruG"
   ],
   "id": "119e2e41d321c794",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearActivationQuantizedTensor(AffineQuantizedTensor(tensor_impl=PlainAQTTensorImpl(data=tensor([[ 13,  14,   1,  ...,  -1,   7,   9],\n",
      "        [-12, -19,   4,  ...,  -9,  -4,   1],\n",
      "        [ 10,  11,  13,  ...,   5,   2,  13],\n",
      "        ...,\n",
      "        [  0,   5,  11,  ...,   4,  -3,   7],\n",
      "        [  5,  16,   3,  ...,   4,  10,  20],\n",
      "        [ -6,  14,   9,  ...,   3,   6,   1]], device='mps:0',\n",
      "       dtype=torch.int8)... , scale=tensor([0.0029, 0.0024, 0.0022, 0.0013, 0.0024, 0.0016, 0.0021, 0.0014, 0.0020,\n",
      "        0.0016, 0.0019, 0.0020, 0.0027, 0.0004, 0.0015, 0.0020, 0.0012, 0.0027,\n",
      "        0.0022, 0.0019, 0.0021, 0.0020, 0.0023, 0.0006, 0.0015, 0.0022, 0.0004,\n",
      "        0.0031, 0.0003, 0.0020, 0.0023, 0.0029, 0.0021, 0.0005, 0.0017, 0.0022,\n",
      "        0.0026, 0.0040, 0.0014, 0.0034, 0.0019, 0.0017, 0.0020, 0.0026, 0.0005,\n",
      "        0.0018, 0.0004, 0.0038, 0.0017, 0.0018, 0.0021, 0.0028, 0.0021, 0.0019,\n",
      "        0.0026, 0.0017, 0.0019, 0.0033, 0.0013, 0.0016, 0.0022, 0.0021, 0.0007,\n",
      "        0.0016, 0.0004, 0.0018, 0.0021, 0.0017, 0.0024, 0.0004, 0.0014, 0.0022,\n",
      "        0.0024, 0.0017, 0.0017, 0.0021, 0.0022, 0.0022, 0.0016, 0.0023, 0.0020,\n",
      "        0.0004, 0.0023, 0.0028, 0.0031, 0.0022, 0.0020, 0.0027, 0.0018, 0.0022,\n",
      "        0.0015, 0.0018, 0.0038, 0.0015, 0.0030, 0.0018, 0.0027, 0.0003, 0.0016,\n",
      "        0.0021, 0.0024, 0.0019, 0.0025, 0.0013, 0.0020, 0.0019, 0.0019, 0.0022,\n",
      "        0.0022, 0.0015, 0.0026, 0.0019, 0.0020, 0.0022, 0.0028, 0.0025, 0.0026,\n",
      "        0.0017, 0.0021, 0.0020, 0.0006, 0.0020, 0.0034, 0.0018, 0.0018, 0.0044,\n",
      "        0.0028, 0.0023], device='mps:0')... , zero_point=None... , _layout=PlainLayout()), block_size=(1, 784), shape=torch.Size([128, 784]), device=mps:0, dtype=torch.float32, requires_grad=False), <function _int8_symm_per_token_reduced_range_quant at 0x167401f30>, quant_kwargs={}))\n",
      "Parameter containing:\n",
      "tensor([-0.0125,  0.0362,  0.0010, -0.0220, -0.0636, -0.0202,  0.0311, -0.0310,\n",
      "        -0.0279, -0.0124,  0.0104,  0.0056,  0.0190, -0.0433, -0.0403, -0.0144,\n",
      "        -0.0422, -0.0489,  0.0070,  0.0476,  0.0027, -0.0185,  0.0521, -0.0434,\n",
      "        -0.0529, -0.0260, -0.0357, -0.0259, -0.0414, -0.0560,  0.0050, -0.0021,\n",
      "        -0.0013, -0.0516, -0.0169,  0.0261, -0.0083,  0.0039,  0.0015, -0.0128,\n",
      "         0.0150,  0.0152, -0.0263,  0.0036, -0.0391,  0.0013,  0.0054, -0.0354,\n",
      "        -0.0197, -0.0365,  0.0183, -0.0095, -0.0515,  0.0193, -0.0401, -0.0258,\n",
      "        -0.0026,  0.0073, -0.0221, -0.0204,  0.0244, -0.0195, -0.0295, -0.0185,\n",
      "        -0.0328, -0.0011, -0.0449, -0.0156,  0.0027,  0.0055, -0.0020,  0.0170,\n",
      "         0.0305, -0.0180, -0.0360, -0.0163, -0.0066, -0.0115, -0.0273,  0.0113,\n",
      "        -0.0047, -0.0318, -0.0680, -0.0423,  0.0062,  0.0374, -0.0256, -0.0036,\n",
      "        -0.0615, -0.0452,  0.0212, -0.0198, -0.0213,  0.0257, -0.0031, -0.0675,\n",
      "         0.0320,  0.0167, -0.0200, -0.0426, -0.0401, -0.0167,  0.0092, -0.0597,\n",
      "        -0.0090, -0.0219,  0.0069, -0.0165,  0.0375,  0.0109,  0.0306, -0.0130,\n",
      "        -0.0311,  0.0086,  0.0185,  0.0162, -0.0192, -0.0236, -0.0297, -0.0042,\n",
      "        -0.0669, -0.0272,  0.0122, -0.0574, -0.0008, -0.0544, -0.0315, -0.0061],\n",
      "       device='mps:0', requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### dequantised outputs",
   "id": "9b0846da9d9f64e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:30:55.445045Z",
     "start_time": "2025-12-16T18:30:55.330155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def activation_hook(name):\n",
    "    def hook(module, inp, out):\n",
    "        print(out.dtype)\n",
    "        print(out)\n",
    "    return hook\n",
    "\n",
    "q_net.eval()\n",
    "hook_handle = q_net.linear1.register_forward_hook(\n",
    "    activation_hook(\"linear3\")\n",
    ")\n",
    "\n",
    "iterations = 1\n",
    "for idx, (x, y) in enumerate(tqdm(train_loader, desc='Inspection')):\n",
    "    if idx >= iterations:\n",
    "        break\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    q_net(x)\n",
    "\n",
    "hook_handle.remove()"
   ],
   "id": "d9552087a27594be",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inspection:   0%|          | 1/6000 [00:00<10:59,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[ -3.1619,  -5.2125,  -2.5498,  ...,  -4.8291, -12.8415,  -3.8565],\n",
      "        [ -9.3881,  -6.7253, -16.2016,  ..., -13.1316, -18.7740,  -3.7072],\n",
      "        [ 10.8166,   2.4249,  10.6563,  ...,  -1.0033,  -3.9378,  -4.4136],\n",
      "        ...,\n",
      "        [-15.1940,  -0.6169,  -7.4738,  ...,  -7.8985,  -1.1337,  -6.4681],\n",
      "        [ 13.4286,  -2.4671,  10.0608,  ...,  -1.0275,  -6.8543,  -7.2977],\n",
      "        [ -4.1664,   8.4670,  -9.4396,  ..., -10.8934, -13.6064, -12.9925]],\n",
      "       device='mps:0', grad_fn=<AsStridedBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Comparisons",
   "id": "555465103232a3a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:31:43.322757Z",
     "start_time": "2025-12-16T18:30:57.907643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Test Evaluation on Original Model\")\n",
    "test(net)\n",
    "print(\"Test Evaluation on Quantised Model\")\n",
    "test(q_net)"
   ],
   "id": "ba006c93ed40750a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Evaluation on Original Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:05<00:00, 174.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "Test Evaluation on Quantised Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:39<00:00, 25.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:32:12.524183Z",
     "start_time": "2025-12-16T18:32:12.497553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Size of Original Model\")\n",
    "print_size_of_model(net)\n",
    "print(\"Size of Quantized Model\")\n",
    "print_size_of_model(q_net)"
   ],
   "id": "95330f2cdd5674e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Original Model\n",
      "Size (KB): 476.153\n",
      "Size of Quantized Model\n",
      "Size (KB): 125.366\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
